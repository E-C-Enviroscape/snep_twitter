---
title: "What ecosystem services do people in the SNEP region care about?"
date: "3/18/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## this chunk loads all of the packages we need

## for twitter word search
library(rtweet) # install.packages("rtweet")

## load text mining library
library(tidytext) # install.packages("tidytext")

## plotting packages
library(tidyverse, igraph) # install.packages("tidyverse", "igraph")

```

## What ecosystem services do people in the SNEP region care about?

We picked these words that might indicate general interest, concern, or focus of 
Twitter users in the SNEP region (Westerly, RI to Cape Cod, MA).

We are examining Twitter data one day every week from March to August 2020 to 
determine which words (representing ecosystem services) are the most popular. We will be using the 
[rtweet package](https://rtweet.info/) in R to do this. Here is the list of words:

* swimming
* hiking
* boating
* kayaking
* fishing
* ferry
* ocean
* beach
* wave
* wetland
* seaweed
* river
* bay
* forest
* seafood
* beach closure
* red tide
* nor'easter
* flooding
* drought
* tide
* seal

***

```{r stopwords, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)

## running list of words that contain snep words but aren't of interest

mystopwords <- tibble(word = c("driver", "drivers", "hitchhiking", "sealed", 
                               "unwavering", "microwave", "waverly", "waved", 
                               "#ebay", "#bluewave2020", "bayek", "#busdriver", 
                               "bayer", "unsealed", "smithrivera", "seales", 
                               "rainforests", "rainforest", "rivera", "riverside", 
                               "#bluewave"))

```

Here's the first try at mining Twitter data and quantifying SNEP words:

```{r words_mar6, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)

## need google maps API to get georeferenced tweets

## search for 18,000 tweets in RI and MA
# mar6 <- search_tweets("lang:en", geocode = lookup_coords("rhode island", "massachusetts", apikey = "AIzaSyDekm4ATG_9Ir0N1VGuNo8accyKrnttbDU" ), n = 18000, include_rts = FALSE)

## remove http elements manually
mar6$text <- gsub("http.*","",  mar6$text)
mar6$text <- gsub("https.*","", mar6$text)

## create list of words and make tidy
mar6_words <- mar6 %>%
  dplyr::select(text) %>%
  unnest_tokens(word, text, token = "tweets") %>%
  filter(!word %in% stop_words$word,
         !word %in% str_remove_all(stop_words$word, "'"),
         str_detect(word , "[a-z]"))

## filter out stopwords and emojis
mar6_words$word <- sapply(mar6_words$word,function(row) iconv(row, "latin1", "ASCII", sub=""))

mar6_words <- anti_join(mar6_words, mystopwords, 
                           by = "word")

## filter out all other words besides snep_words
mar6_snep <- mar6_words %>% 
  filter(str_detect(word, "swimming|hiking|boating|kayaking|fishing|ferry|ocean|beach|wave|wetland|seaweed|river|bay|forest|seafood|beach closure|red tide|noreaster|flooding|drought|tide|seal"))

## filter out usernames and emojis
mar6_snep <- str_remove(mar6_snep$word, "@.*") %>%
  data.frame(lapply(mar6_snep, as.character), stringsAsFactors=FALSE)

## remove blanks
mar6_snep <- mar6_snep[!(is.na(mar6_snep$.) | mar6_snep$.==""), ]

## select single column and rename
mar6_snep <- select(mar6_snep, .) %>%
  rename(word = 1)

## add a date column and save for adding to future months!
mar6_snep$date <- "march 6 2020"
write.csv(mar6_snep,"data/mar6_snep.csv", row.names = FALSE)

## summarize by word frequency
mar6_freq <- mar6_snep %>%
  group_by(word) %>%
  count(word, sort = TRUE) %>%
  left_join(mar6_snep %>%
              group_by(word) %>%
              summarise())

write.csv(mar6_freq,"data/mar6_freq.csv", row.names = FALSE)

## plot top words
mar6_plot <- mar6_snep %>%
  count(word, sort = TRUE) %>%
  top_n(15) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(x = word, y = n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip() +
      labs(y = "Count",
      x = "Top SNEP Key Words",
      title = "March 6, 2020: Count of SNEP key words found in tweets")

mar6_plot

ggsave("figures/mar6_plot.png", dpi = 200)

```

And now repeating these methods for the following week:

```{r words_mar11, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)

## need google maps API to get georeferenced tweets

## search for 18,000 tweets in RI and MA
# mar11 <- search_tweets("lang:en", geocode = lookup_coords("rhode island", "massachusetts", apikey = "AIzaSyDekm4ATG_9Ir0N1VGuNo8accyKrnttbDU" ), n = 18000, include_rts = FALSE)

## remove http elements manually
mar11$text <- gsub("http.*","",  mar11$text)
mar11$text <- gsub("https.*","", mar11$text)

## create list of words and make tidy
mar11_words <- mar11 %>%
  dplyr::select(text) %>%
  unnest_tokens(word, text, token = "tweets") %>%
  filter(!word %in% stop_words$word,
         !word %in% str_remove_all(stop_words$word, "'"),
         str_detect(word , "[a-z]"))

## filter out stopwords and emojis
mar11_words <- anti_join(mar11_words, mystopwords, 
                           by = "word")

mar6_words$word <- sapply(mar6_words$word,function(row) iconv(row, "latin1", "ASCII", sub=""))

## filter out all other words besides snep_words
mar11_snep <- mar11_words %>% 
  filter(str_detect(word, "swimming|hiking|boating|kayaking|fishing|ferry|ocean|beach|wave|wetland|seaweed|river|bay|forest|seafood|beach closure|red tide|noreaster|flooding|drought|tide|seal"))

## filter out usernames
mar11_snep <- str_remove(mar11_snep$word, "@.*") %>%
  data.frame(lapply(mar11_snep, as.character), stringsAsFactors=FALSE)

## remove blanks
mar11_snep <- mar11_snep[!(is.na(mar11_snep$.) | mar11_snep$.==""), ]

## select single column and rename
mar11_snep <- select(mar11_snep, .) %>%
  rename(word = 1)

## add a date column and save for adding to future months!
mar11_snep$date <- "march 11 2020"
write.csv(mar11_snep,"data/mar11_snep.csv", row.names = FALSE)

## summarize by word frequency
mar11_freq <- mar11_snep %>%
  group_by(word) %>%
  count(word, sort = TRUE) %>%
  left_join(mar11_snep %>%
             group_by(word) %>%
              summarise())

write.csv(mar11_freq,"data/mar11_freq.csv", row.names = FALSE)

## plot top words
mar11_plot <- mar11_snep %>%
  count(word, sort = TRUE) %>%
  top_n(12) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(x = word, y = n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip() +
      labs(y = "Count",
      x = "Top SNEP Key Words",
      title = "March 11, 2020: Count of SNEP key words found in tweets")

mar11_plot

ggsave("figures/mar11_plot.png", dpi = 200)

```

Now create a combined table and plot showing the cumulative data.

```{r words_all, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)

## merge all of the weekly data into a single data frame
all_snep <- rbind(mar6_snep, mar11_snep)

## summarize by word frequency
allsnep_freq <- all_snep %>%
  group_by(word) %>%
  count(word, sort = TRUE) %>%
  left_join(all_snep %>%
             group_by(word) %>%
              summarise())

write.csv(allsnep_freq,"data/allsnep_freq.csv", row.names = FALSE)

## plot top words
allsnep_plot <- all_snep %>%
  count(word, sort = TRUE) %>%
  top_n(15) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(x = word, y = n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip() +
      labs(y = "Count",
      x = "Top SNEP Key Words",
      title = "March 6-11, 2020: Count of SNEP key words found in tweets")

allsnep_plot
ggsave("figures/allsnep_plot.png", dpi = 200)

```
